{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Inference_examples.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Machine Learning for Physical Sciences\n",
    "*pip install mlphys*\n",
    "\n",
    "Author: Sanjaya Lohani\n",
    "\n",
    "*Please report bugs at slohani@mlphys.com\n",
    "\n",
    "Papers:\n",
    "\n",
    "1.   Lohani, S., Lukens, J.M., Jones, D.E., Searles, T.A., Glasser, R.T. and Kirby, B.T., 2021. Improving application performance with biased distributions of quantum states. *Physical Review Research*, 3(4), p.043145. \n",
    "\n",
    "2.  Lohani, S., Searles, T. A., Kirby, B. T., & Glasser, R. T. (2021). On the Experimental Feasibility of Quantum State Reconstruction via Machine Learning. *IEEE Transactions on Quantum Engineering*, 2, 1â€“10. \n",
    "\n",
    "Collaborator: Joseph M. Lukens, Daniel E. Jones, Ryan T. Glasser, Thomas A. Searles, and Brian T. Kirby\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "to8czZ-hqNwv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11eJ2p0Ek8N9"
   },
   "outputs": [],
   "source": [
    "!pip install mlphys"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import deepqis.Simulator.Distributions as dist\n",
    "import deepqis.Simulator.Measurements as meas\n",
    "import matplotlib.pyplot as plt\n",
    "import deepqis.utils.Alpha_Measure as find_alpha\n",
    "import deepqis.utils.Concurrence_Measure as find_con\n",
    "import deepqis.utils.Purity_Measure as find_pm\n",
    "import deepqis.network.inference as inference\n",
    "import deepqis.utils.Fidelity_Measure as fm"
   ],
   "metadata": {
    "id": "vilukIJNlMDT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Generating 100 test sets \n",
    "# Random measurements = 1000. \n",
    "#\"\"\" NOTE: The Random measurements illustrate the use of a single basis chosen \n",
    "# randomly at a time, which is different from the term \"shots\" used in NISQ. \n",
    "#\"\"\"\n",
    "\n",
    "# 1. Bures and its tomography \n",
    "bures = dist.Bures(qs=2).sample_dm(100)\n",
    "tomo_bures,_ = meas.Random_Measurements(qs=2, n_meas=1000).tomography_data(bures)\n",
    "\n",
    "# 2. HS\n",
    "hs = dist.Hilbert_Schmidt(qs=2).sample_dm(100)\n",
    "tomo_hs,_ = meas.Random_Measurements(qs=2, n_meas=1000).tomography_data(hs)\n",
    "\n",
    "#3. Haar random pure states\n",
    "haar = dist.Haar_State(qs=2).sample_dm(100)\n",
    "tomo_haar,_ = meas.Random_Measurements(qs=2, n_meas=1000).tomography_data(haar)\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tRVjYETlSyP",
    "outputId": "31050bff-3fe1-42e5-959f-b840fbc44cce"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "| To accelerate the simulation, General Scheme Projector file is created in utils folder.\n",
      "| To accelerate the simulation, General Scheme Projector file is created in utils folder.\n",
      "| To accelerate the simulation, General Scheme Projector file is created in utils folder.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### To demonstrate the efficacy of biased distributions, we have inculded only two alpha \n",
    "\n",
    "---\n",
    "\n",
    "values at the moment. $\\alpha = 0.1, 0.4$\n",
    "\n",
    "##### 1. Reconstructing States using a pre-trained model with MA at $\\alpha = 0.1$\n",
    "\n"
   ],
   "metadata": {
    "id": "I6BqIIoVtcRC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pred_bures, _ = inference.fit(tomo_bures, alpha=0.1)\n",
    "pred_hs, _ = inference.fit(tomo_hs, alpha=0.1)\n",
    "pred_haar, model = inference.fit(tomo_haar, alpha=0.1)\n",
    "\n",
    "print ('*'*100)\n",
    "\n",
    "_, fid_bures_av = fm.Fidelity_Metric(bures, pred_bures)\n",
    "print(\"Mean Fidelity for Bures: \", fid_bures_av)\n",
    "\n",
    "_, fid_hs_av = fm.Fidelity_Metric(hs, pred_hs)\n",
    "print(\"Mean Fidelity for HS: \", fid_hs_av)\n",
    "\n",
    "_, fid_haar_av = fm.Fidelity_Metric(haar, pred_haar)\n",
    "print(\"Mean Fidelity for Haar: \", fid_haar_av)\n",
    "print ('*'*100)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yzi3T-YqnIR9",
    "outputId": "71d47fcb-6c9f-41a0-fb3c-dc80611dfcae"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "****************************************************************************************************\n",
      "Mean Fidelity for Bures:  tf.Tensor(0.8968013307455044, shape=(), dtype=float64)\n",
      "Mean Fidelity for HS:  tf.Tensor(0.8811446723795896, shape=(), dtype=float64)\n",
      "Mean Fidelity for Haar:  tf.Tensor(0.9746848419301074, shape=(), dtype=float64)\n",
      "****************************************************************************************************\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. Reconstructing States using a pre-trained model with MA at $\\alpha = 0.4$"
   ],
   "metadata": {
    "id": "tmWWrjUhAAkR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pred_bures, _ = inference.fit(tomo_bures, alpha=0.4)\n",
    "pred_hs, _ = inference.fit(tomo_hs, alpha=0.4)\n",
    "pred_haar, model = inference.fit(tomo_haar, alpha=0.4)\n",
    "\n",
    "print ('*'*100)\n",
    "\n",
    "_, fid_bures_av = fm.Fidelity_Metric(bures, pred_bures)\n",
    "print(\"Mean Fidelity for Bures: \", fid_bures_av)\n",
    "\n",
    "_, fid_hs_av = fm.Fidelity_Metric(hs, pred_hs)\n",
    "print(\"Mean Fidelity for HS: \", fid_hs_av)\n",
    "\n",
    "_, fid_haar_av = fm.Fidelity_Metric(haar, pred_haar)\n",
    "print(\"Mean Fidelity for Haar: \", fid_haar_av)\n",
    "print ('*'*100)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rDkH9LzSBMGn",
    "outputId": "729270a8-102a-46ba-b739-6974d5dd5904"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "****************************************************************************************************\n",
      "Mean Fidelity for Bures:  tf.Tensor(0.9434581823439455, shape=(), dtype=float64)\n",
      "Mean Fidelity for HS:  tf.Tensor(0.9378521719517291, shape=(), dtype=float64)\n",
      "Mean Fidelity for Haar:  tf.Tensor(0.9411295372226925, shape=(), dtype=float64)\n",
      "****************************************************************************************************\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View the model used. \n"
   ],
   "metadata": {
    "id": "5WhfUu4sDrkD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5WZTwja8FAu",
    "outputId": "9e292a4e-a94f-4200-c96d-098dfe5ed5c3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"ARL_Nets\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Tomography_Measurements (In  [(None, 6, 6, 1)]        0         \n",
      " putLayer)                                                       \n",
      "                                                                 \n",
      " First_CONV (Conv2D)         (None, 6, 6, 64)          320       \n",
      "                                                                 \n",
      " First_MAXPOOL (MaxPooling2D  (None, 3, 3, 64)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " Second_CONV (Conv2D)        (None, 3, 3, 64)          16448     \n",
      "                                                                 \n",
      " FLATTEN (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " First_DENSE (Dense)         (None, 3000)              1731000   \n",
      "                                                                 \n",
      " First_DROPOUT (Dropout)     (None, 3000)              0         \n",
      "                                                                 \n",
      " Sec_DENSE (Dense)           (None, 1200)              3601200   \n",
      "                                                                 \n",
      " Sec_DROPOUT (Dropout)       (None, 1200)              0         \n",
      "                                                                 \n",
      " Tau_Elements (Dense)        (None, 16)                19216     \n",
      "                                                                 \n",
      " Density_Matrix (PredictDens  (None, 4, 4)             0         \n",
      " ityMatrix)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,368,184\n",
      "Trainable params: 5,368,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The tensorflow model can also be directly imported from the 'load' module. After that it can be used in fine tuning any other network-settings and training scenarios."
   ],
   "metadata": {
    "id": "qwhuTS4jBjMB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from deepqis.utils import Extract_Net\n",
    "model_h5 = inference.load(alpha=0.4)\n",
    "model = tf.keras.models.load_model(model_h5, custom_objects={'ErrorNode':Extract_Net.ErrorNode, \n",
    "                                        'PredictDensityMatrix':Extract_Net.PredictDensityMatrix})\n",
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOTLg8sDCclt",
    "outputId": "160f43c5-f94f-4b4d-cdd3-0c103010351f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"ARL_Nets\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Tomography_Measurements (In  [(None, 6, 6, 1)]        0         \n",
      " putLayer)                                                       \n",
      "                                                                 \n",
      " First_CONV (Conv2D)         (None, 6, 6, 64)          320       \n",
      "                                                                 \n",
      " First_MAXPOOL (MaxPooling2D  (None, 3, 3, 64)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " Second_CONV (Conv2D)        (None, 3, 3, 64)          16448     \n",
      "                                                                 \n",
      " FLATTEN (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " First_DENSE (Dense)         (None, 3000)              1731000   \n",
      "                                                                 \n",
      " First_DROPOUT (Dropout)     (None, 3000)              0         \n",
      "                                                                 \n",
      " Sec_DENSE (Dense)           (None, 1200)              3601200   \n",
      "                                                                 \n",
      " Sec_DROPOUT (Dropout)       (None, 1200)              0         \n",
      "                                                                 \n",
      " Tau_Elements (Dense)        (None, 16)                19216     \n",
      "                                                                 \n",
      " Density_Matrix (PredictDens  (None, 4, 4)             0         \n",
      " ityMatrix)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,368,184\n",
      "Trainable params: 5,368,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  }
 ]
}