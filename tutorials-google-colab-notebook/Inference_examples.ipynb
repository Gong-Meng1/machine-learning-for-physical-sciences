{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Inference_examples.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Machine Learning for Physical Sciences\n",
    "*pip install mlphys*\n",
    "\n",
    "Author: Sanjaya Lohani\n",
    "\n",
    "*Please report bugs at slohani@mlphys.com\n",
    "\n",
    "Papers:\n",
    "\n",
    "1.   Lohani, S., Lukens, J.M., Jones, D.E., Searles, T.A., Glasser, R.T. and Kirby, B.T., 2021. Improving application performance with biased distributions of quantum states. *Physical Review Research*, 3(4), p.043145. \n",
    "\n",
    "2.  Lohani, S., Searles, T. A., Kirby, B. T., & Glasser, R. T. (2021). On the Experimental Feasibility of Quantum State Reconstruction via Machine Learning. *IEEE Transactions on Quantum Engineering*, 2, 1–10. \n",
    "\n",
    "Collaborator: Joseph M. Lukens, Daniel E. Jones, Ryan T. Glasser, Thomas A. Searles, and Brian T. Kirby\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "to8czZ-hqNwv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11eJ2p0Ek8N9",
    "outputId": "bf1e28f0-d531-406e-9551-92e397dacd28"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting mlphys\n",
      "  Downloading mlphys-0.0.36.tar.gz (39.9 MB)\n",
      "\u001B[K     |████████████████████████████████| 39.9 MB 1.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from mlphys) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (from mlphys) (0.15.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlphys) (1.19.5)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlphys) (1.1.5)\n",
      "Collecting qiskit\n",
      "  Downloading qiskit-0.34.1.tar.gz (13 kB)\n",
      "Collecting twine\n",
      "  Downloading twine-3.7.1-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->mlphys) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mlphys) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->mlphys) (1.15.0)\n",
      "Collecting qiskit-terra==0.19.1\n",
      "  Downloading qiskit_terra-0.19.1-cp37-cp37m-manylinux2010_x86_64.whl (6.4 MB)\n",
      "\u001B[K     |████████████████████████████████| 6.4 MB 30.8 MB/s \n",
      "\u001B[?25hCollecting qiskit-aer==0.10.2\n",
      "  Downloading qiskit_aer-0.10.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (18.0 MB)\n",
      "\u001B[K     |████████████████████████████████| 18.0 MB 663 kB/s \n",
      "\u001B[?25hCollecting qiskit-ibmq-provider==0.18.3\n",
      "  Downloading qiskit_ibmq_provider-0.18.3-py3-none-any.whl (238 kB)\n",
      "\u001B[K     |████████████████████████████████| 238 kB 68.5 MB/s \n",
      "\u001B[?25hCollecting qiskit-ignis==0.7.0\n",
      "  Downloading qiskit_ignis-0.7.0-py3-none-any.whl (200 kB)\n",
      "\u001B[K     |████████████████████████████████| 200 kB 61.9 MB/s \n",
      "\u001B[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-aer==0.10.2->qiskit->mlphys) (1.4.1)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.3->qiskit->mlphys) (1.24.3)\n",
      "Collecting requests-ntlm>=1.1.0\n",
      "  Downloading requests_ntlm-1.1.0-py2.py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.18.3->qiskit->mlphys) (2.23.0)\n",
      "Collecting websocket-client>=1.0.1\n",
      "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
      "\u001B[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ignis==0.7.0->qiskit->mlphys) (57.4.0)\n",
      "Collecting retworkx>=0.8.0\n",
      "  Downloading retworkx-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.6 MB 53.2 MB/s \n",
      "\u001B[?25hCollecting tweedledum<2.0,>=1.1\n",
      "  Downloading tweedledum-1.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (943 kB)\n",
      "\u001B[K     |████████████████████████████████| 943 kB 49.2 MB/s \n",
      "\u001B[?25hCollecting stevedore>=3.0.0\n",
      "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
      "\u001B[K     |████████████████████████████████| 49 kB 5.9 MB/s \n",
      "\u001B[?25hRequirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.19.1->qiskit->mlphys) (1.7.1)\n",
      "Collecting ply>=3.10\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "\u001B[K     |████████████████████████████████| 49 kB 5.7 MB/s \n",
      "\u001B[?25hRequirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.19.1->qiskit->mlphys) (5.4.8)\n",
      "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.19.1->qiskit->mlphys) (0.3.4)\n",
      "Collecting scipy>=1.0\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "\u001B[K     |████████████████████████████████| 38.1 MB 1.3 MB/s \n",
      "\u001B[?25hCollecting python-constraint>=1.4\n",
      "  Downloading python-constraint-1.4.0.tar.bz2 (18 kB)\n",
      "Collecting symengine>=0.8\n",
      "  Downloading symengine-0.8.1-cp37-cp37m-manylinux2010_x86_64.whl (38.2 MB)\n",
      "\u001B[K     |████████████████████████████████| 38.2 MB 1.4 MB/s \n",
      "\u001B[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.18.3->qiskit->mlphys) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.18.3->qiskit->mlphys) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.18.3->qiskit->mlphys) (3.0.4)\n",
      "Collecting cryptography>=1.3\n",
      "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
      "\u001B[K     |████████████████████████████████| 3.6 MB 51.2 MB/s \n",
      "\u001B[?25hCollecting ntlm-auth>=1.0.2\n",
      "  Downloading ntlm_auth-1.5.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.18.3->qiskit->mlphys) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.18.3->qiskit->mlphys) (2.21)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.8.0-py2.py3-none-any.whl (112 kB)\n",
      "\u001B[K     |████████████████████████████████| 112 kB 73.3 MB/s \n",
      "\u001B[?25hRequirement already satisfied: importlib-metadata>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from stevedore>=3.0.0->qiskit-terra==0.19.1->qiskit->mlphys) (4.10.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0->stevedore>=3.0.0->qiskit-terra==0.19.1->qiskit->mlphys) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.7.0->stevedore>=3.0.0->qiskit-terra==0.19.1->qiskit->mlphys) (3.10.0.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.3->qiskit-terra==0.19.1->qiskit->mlphys) (1.2.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (3.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (2.7.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (2.7.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (1.0.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (12.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (0.37.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (0.2.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (0.23.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (3.17.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (1.43.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (1.13.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->mlphys) (1.6.3)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->mlphys) (1.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->mlphys) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->mlphys) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->mlphys) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->mlphys) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->mlphys) (1.0.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->mlphys) (1.35.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->mlphys) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->mlphys) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->mlphys) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->mlphys) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->mlphys) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->mlphys) (3.1.1)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->mlphys) (1.3.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->mlphys) (4.4.2)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->mlphys) (0.1.6)\n",
      "Collecting rfc3986>=1.4.0\n",
      "  Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting keyring>=15.1\n",
      "  Downloading keyring-23.5.0-py3-none-any.whl (33 kB)\n",
      "Collecting requests-toolbelt!=0.9.0,>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "\u001B[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
      "\u001B[?25hCollecting colorama>=0.4.3\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: tqdm>=4.14 in /usr/local/lib/python3.7/dist-packages (from twine->mlphys) (4.62.3)\n",
      "Collecting pkginfo>=1.8.1\n",
      "  Downloading pkginfo-1.8.2-py2.py3-none-any.whl (26 kB)\n",
      "Collecting readme-renderer>=21.0\n",
      "  Downloading readme_renderer-32.0-py3-none-any.whl (16 kB)\n",
      "Collecting SecretStorage>=3.2\n",
      "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Downloading jeepney-0.7.1-py3-none-any.whl (54 kB)\n",
      "\u001B[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
      "\u001B[?25hRequirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine->mlphys) (0.17.1)\n",
      "Requirement already satisfied: Pygments>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine->mlphys) (2.6.1)\n",
      "Requirement already satisfied: bleach>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine->mlphys) (4.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach>=2.1.0->readme-renderer>=21.0->twine->mlphys) (21.3)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach>=2.1.0->readme-renderer>=21.0->twine->mlphys) (0.5.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach>=2.1.0->readme-renderer>=21.0->twine->mlphys) (3.0.7)\n",
      "Building wheels for collected packages: mlphys, qiskit, python-constraint\n",
      "  Building wheel for mlphys (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for mlphys: filename=mlphys-0.0.36-py3-none-any.whl size=39864524 sha256=bd8d5b253a9e9845e2846d43760d69a95cb8ab2d3a9be368dfabae5157c1de09\n",
      "  Stored in directory: /root/.cache/pip/wheels/35/fd/89/4eb04e64393d3e7b3d5fb2b8a3bdaeb20f3f74a055ee0692fa\n",
      "  Building wheel for qiskit (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for qiskit: filename=qiskit-0.34.1-py3-none-any.whl size=11771 sha256=e4b4d4718ce31c3f3ce25b601a7ec985cf88c2fac35cbb66bd3792304b6b4941\n",
      "  Stored in directory: /root/.cache/pip/wheels/79/b1/3f/8cdfd5543a84705e4bd16e081f2362b9b3bfd9898d2e2d4150\n",
      "  Building wheel for python-constraint (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for python-constraint: filename=python_constraint-1.4.0-py2.py3-none-any.whl size=24081 sha256=7d64b704a4fd07a2693739aa81d80ce16fdc17574a33c88ca9a611cdbedf29d5\n",
      "  Stored in directory: /root/.cache/pip/wheels/07/27/db/1222c80eb1e431f3d2199c12569cb1cac60f562a451fe30479\n",
      "Successfully built mlphys qiskit python-constraint\n",
      "Installing collected packages: pbr, tweedledum, symengine, stevedore, scipy, retworkx, python-constraint, ply, ntlm-auth, jeepney, cryptography, websocket-client, SecretStorage, requests-ntlm, qiskit-terra, rfc3986, requests-toolbelt, readme-renderer, qiskit-ignis, qiskit-ibmq-provider, qiskit-aer, pkginfo, keyring, colorama, twine, qiskit, mlphys\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.4.1\n",
      "    Uninstalling scipy-1.4.1:\n",
      "      Successfully uninstalled scipy-1.4.1\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001B[0m\n",
      "Successfully installed SecretStorage-3.3.1 colorama-0.4.4 cryptography-36.0.1 jeepney-0.7.1 keyring-23.5.0 mlphys-0.0.36 ntlm-auth-1.5.0 pbr-5.8.0 pkginfo-1.8.2 ply-3.11 python-constraint-1.4.0 qiskit-0.34.1 qiskit-aer-0.10.2 qiskit-ibmq-provider-0.18.3 qiskit-ignis-0.7.0 qiskit-terra-0.19.1 readme-renderer-32.0 requests-ntlm-1.1.0 requests-toolbelt-0.9.1 retworkx-0.11.0 rfc3986-2.0.0 scipy-1.7.3 stevedore-3.5.0 symengine-0.8.1 tweedledum-1.1.1 twine-3.7.1 websocket-client-1.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install mlphys"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import deepqis.Simulator.Distributions as dist\n",
    "import deepqis.Simulator.Measurements as meas\n",
    "import matplotlib.pyplot as plt\n",
    "import deepqis.utils.Alpha_Measure as find_alpha\n",
    "import deepqis.utils.Concurrence_Measure as find_con\n",
    "import deepqis.utils.Purity_Measure as find_pm\n",
    "import deepqis.network.inference as inference\n",
    "import deepqis.utils.Fidelity_Measure as fm"
   ],
   "metadata": {
    "id": "vilukIJNlMDT"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Generating 100 test sets \n",
    "# Random measurements = 1000. \n",
    "#\"\"\" NOTE: The Random measurements illustrate the use of a single basis chosen \n",
    "# randomly at a time, which is different from the term \"shots\" used in NISQ. \n",
    "#\"\"\"\n",
    "\n",
    "# 1. Bures and its tomography \n",
    "bures = dist.Bures(qs=2).sample_dm(100)\n",
    "tomo_bures,_ = meas.Random_Measurements(qs=2, n_meas=1000).tomography_data(bures)\n",
    "\n",
    "# 2. HS\n",
    "hs = dist.Hilbert_Schmidt(qs=2).sample_dm(100)\n",
    "tomo_hs,_ = meas.Random_Measurements(qs=2, n_meas=1000).tomography_data(hs)\n",
    "\n",
    "#3. Haar random pure states\n",
    "haar = dist.Haar_State(qs=2).sample_dm(100)\n",
    "tomo_haar,_ = meas.Random_Measurements(qs=2, n_meas=1000).tomography_data(haar)\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tRVjYETlSyP",
    "outputId": "31050bff-3fe1-42e5-959f-b840fbc44cce"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "| To accelerate the simulation, General Scheme Projector file is created in utils folder.\n",
      "| To accelerate the simulation, General Scheme Projector file is created in utils folder.\n",
      "| To accelerate the simulation, General Scheme Projector file is created in utils folder.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### To demonstrate the efficacy of biased distributions, we have included only two alpha values at the moment. $\\alpha = 0.1, 0.4$\n",
    "\n",
    "##### 1. Reconstructing States using a pre-trained model with MA at $\\alpha = 0.1$\n",
    "\n"
   ],
   "metadata": {
    "id": "I6BqIIoVtcRC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pred_bures, _ = inference.fit(tomo_bures, alpha=0.1)\n",
    "pred_hs, _ = inference.fit(tomo_hs, alpha=0.1)\n",
    "pred_haar, model = inference.fit(tomo_haar, alpha=0.1)\n",
    "\n",
    "print ('*'*100)\n",
    "\n",
    "_, fid_bures_av = fm.Fidelity_Metric(bures, pred_bures)\n",
    "print(\"Mean Fidelity for Bures: \", fid_bures_av)\n",
    "\n",
    "_, fid_hs_av = fm.Fidelity_Metric(hs, pred_hs)\n",
    "print(\"Mean Fidelity for HS: \", fid_hs_av)\n",
    "\n",
    "_, fid_haar_av = fm.Fidelity_Metric(haar, pred_haar)\n",
    "print(\"Mean Fidelity for Haar: \", fid_haar_av)\n",
    "print ('*'*100)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yzi3T-YqnIR9",
    "outputId": "71d47fcb-6c9f-41a0-fb3c-dc80611dfcae"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "****************************************************************************************************\n",
      "Mean Fidelity for Bures:  tf.Tensor(0.8968013307455044, shape=(), dtype=float64)\n",
      "Mean Fidelity for HS:  tf.Tensor(0.8811446723795896, shape=(), dtype=float64)\n",
      "Mean Fidelity for Haar:  tf.Tensor(0.9746848419301074, shape=(), dtype=float64)\n",
      "****************************************************************************************************\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 2. Reconstructing States using a pre-trained model with MA at $\\alpha = 0.4$"
   ],
   "metadata": {
    "id": "tmWWrjUhAAkR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pred_bures, _ = inference.fit(tomo_bures, alpha=0.4)\n",
    "pred_hs, _ = inference.fit(tomo_hs, alpha=0.4)\n",
    "pred_haar, model = inference.fit(tomo_haar, alpha=0.4)\n",
    "\n",
    "print ('*'*100)\n",
    "\n",
    "_, fid_bures_av = fm.Fidelity_Metric(bures, pred_bures)\n",
    "print(\"Mean Fidelity for Bures: \", fid_bures_av)\n",
    "\n",
    "_, fid_hs_av = fm.Fidelity_Metric(hs, pred_hs)\n",
    "print(\"Mean Fidelity for HS: \", fid_hs_av)\n",
    "\n",
    "_, fid_haar_av = fm.Fidelity_Metric(haar, pred_haar)\n",
    "print(\"Mean Fidelity for Haar: \", fid_haar_av)\n",
    "print ('*'*100)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rDkH9LzSBMGn",
    "outputId": "729270a8-102a-46ba-b739-6974d5dd5904"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "****************************************************************************************************\n",
      "Mean Fidelity for Bures:  tf.Tensor(0.9434581823439455, shape=(), dtype=float64)\n",
      "Mean Fidelity for HS:  tf.Tensor(0.9378521719517291, shape=(), dtype=float64)\n",
      "Mean Fidelity for Haar:  tf.Tensor(0.9411295372226925, shape=(), dtype=float64)\n",
      "****************************************************************************************************\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View the model used. \n"
   ],
   "metadata": {
    "id": "5WhfUu4sDrkD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q5WZTwja8FAu",
    "outputId": "9e292a4e-a94f-4200-c96d-098dfe5ed5c3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"ARL_Nets\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Tomography_Measurements (In  [(None, 6, 6, 1)]        0         \n",
      " putLayer)                                                       \n",
      "                                                                 \n",
      " First_CONV (Conv2D)         (None, 6, 6, 64)          320       \n",
      "                                                                 \n",
      " First_MAXPOOL (MaxPooling2D  (None, 3, 3, 64)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " Second_CONV (Conv2D)        (None, 3, 3, 64)          16448     \n",
      "                                                                 \n",
      " FLATTEN (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " First_DENSE (Dense)         (None, 3000)              1731000   \n",
      "                                                                 \n",
      " First_DROPOUT (Dropout)     (None, 3000)              0         \n",
      "                                                                 \n",
      " Sec_DENSE (Dense)           (None, 1200)              3601200   \n",
      "                                                                 \n",
      " Sec_DROPOUT (Dropout)       (None, 1200)              0         \n",
      "                                                                 \n",
      " Tau_Elements (Dense)        (None, 16)                19216     \n",
      "                                                                 \n",
      " Density_Matrix (PredictDens  (None, 4, 4)             0         \n",
      " ityMatrix)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,368,184\n",
      "Trainable params: 5,368,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The tensorflow model can also be directly imported from the 'load' module. After that it can be used in fine-tuning any other network-settings and training scenarios."
   ],
   "metadata": {
    "id": "qwhuTS4jBjMB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from deepqis.utils import Extract_Net\n",
    "model_h5 = inference.load(alpha=0.4)\n",
    "model = tf.keras.models.load_model(model_h5, custom_objects={'ErrorNode':Extract_Net.ErrorNode, \n",
    "                                        'PredictDensityMatrix':Extract_Net.PredictDensityMatrix})\n",
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JOTLg8sDCclt",
    "outputId": "160f43c5-f94f-4b4d-cdd3-0c103010351f"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:Using a while_loop for converting SparseToDense\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"ARL_Nets\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Tomography_Measurements (In  [(None, 6, 6, 1)]        0         \n",
      " putLayer)                                                       \n",
      "                                                                 \n",
      " First_CONV (Conv2D)         (None, 6, 6, 64)          320       \n",
      "                                                                 \n",
      " First_MAXPOOL (MaxPooling2D  (None, 3, 3, 64)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " Second_CONV (Conv2D)        (None, 3, 3, 64)          16448     \n",
      "                                                                 \n",
      " FLATTEN (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " First_DENSE (Dense)         (None, 3000)              1731000   \n",
      "                                                                 \n",
      " First_DROPOUT (Dropout)     (None, 3000)              0         \n",
      "                                                                 \n",
      " Sec_DENSE (Dense)           (None, 1200)              3601200   \n",
      "                                                                 \n",
      " Sec_DROPOUT (Dropout)       (None, 1200)              0         \n",
      "                                                                 \n",
      " Tau_Elements (Dense)        (None, 16)                19216     \n",
      "                                                                 \n",
      " Density_Matrix (PredictDens  (None, 4, 4)             0         \n",
      " ityMatrix)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,368,184\n",
      "Trainable params: 5,368,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  }
 ]
}